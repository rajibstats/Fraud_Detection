{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general useful packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import matplotlib for visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "#import scikitplot as skplt\n",
    "\n",
    "# Import all machine learning algorithms\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Import other useful subpackage\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loadning data\n",
    "data = pd.read_csv('C:\\\\Users\\\\Purnendu\\\\Desktop\\\\R Code\\\\Python\\\\Fraud Detection\\\\Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>f65</th>\n",
       "      <th>f66</th>\n",
       "      <th>f67</th>\n",
       "      <th>f68</th>\n",
       "      <th>f69</th>\n",
       "      <th>date_time</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>type_A</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>not_valid</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2017-04-18T09:17:44.231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>type_A</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>not_valid</td>\n",
       "      <td>1</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2017-04-08T05:56:06.599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_data</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>type_A</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>not_valid</td>\n",
       "      <td>1</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2017-05-02T16:28:43.207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>type_A</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>not_valid</td>\n",
       "      <td>1</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2017-05-17T06:48:45.574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>type_A</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>not_valid</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2017-05-09T18:53:05.890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f1     f2   f3  f4     f5  f6     f7  f8      f9    f10  ...    f62  \\\n",
       "0     true  False   No   1  False   1  False   1  type_A  False  ...      0   \n",
       "1     true  False   No   1  False   1  False   1  type_A  False  ...      0   \n",
       "2  no_data  False  Yes   1   True   1  False   1  type_A  False  ...      0   \n",
       "3    false  False  Yes   1   True   1  False   1  type_A  False  ...      0   \n",
       "4     true  False  Yes   1   True   1  False   1  type_A  False  ...      0   \n",
       "\n",
       "   f63 f64    f65    f66        f67 f68    f69                date_time  class  \n",
       "0    0   1  false  False  not_valid   1  160.0  2017-04-18T09:17:44.231      0  \n",
       "1    0   1  false  False  not_valid   1  159.0  2017-04-08T05:56:06.599      0  \n",
       "2    0   1  false   True  not_valid   1  118.0  2017-05-02T16:28:43.207      0  \n",
       "3    0   1  false  False  not_valid   1  155.0  2017-05-17T06:48:45.574      0  \n",
       "4    0   1  false   True  not_valid   1  125.0  2017-05-09T18:53:05.890      0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data structure\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4500\n",
      "1     500\n",
      "Name: class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Distribution of Labels on train data\n",
    "ax = sns.countplot(y=data['class'])\n",
    "xx=data['class'].value_counts()\n",
    "print(xx)\n",
    "ax.set_title('Distribution of Labels on data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (5000, 71)\n",
      "Null values present in data: False\n"
     ]
    }
   ],
   "source": [
    "# For training data\n",
    "print(\"Data: {}\".format(data.shape))\n",
    "print(\"Null values present in data: {}\".format(data.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f4</th>\n",
       "      <th>f6</th>\n",
       "      <th>f8</th>\n",
       "      <th>f18</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f23</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>...</th>\n",
       "      <th>f48</th>\n",
       "      <th>f52</th>\n",
       "      <th>f55</th>\n",
       "      <th>f58</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>f68</th>\n",
       "      <th>f69</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.243600</td>\n",
       "      <td>1.155400</td>\n",
       "      <td>1.754200</td>\n",
       "      <td>1.074800</td>\n",
       "      <td>1.272000</td>\n",
       "      <td>548.471622</td>\n",
       "      <td>8.411000</td>\n",
       "      <td>1.101400</td>\n",
       "      <td>1.319600</td>\n",
       "      <td>1.249600</td>\n",
       "      <td>...</td>\n",
       "      <td>1296.837268</td>\n",
       "      <td>0.814454</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>943.182078</td>\n",
       "      <td>1.774800</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>1.148200</td>\n",
       "      <td>1678.807733</td>\n",
       "      <td>0.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.080228</td>\n",
       "      <td>0.767964</td>\n",
       "      <td>1.925753</td>\n",
       "      <td>0.336493</td>\n",
       "      <td>0.631265</td>\n",
       "      <td>888.582893</td>\n",
       "      <td>21.468457</td>\n",
       "      <td>0.666038</td>\n",
       "      <td>0.912153</td>\n",
       "      <td>4.793819</td>\n",
       "      <td>...</td>\n",
       "      <td>3389.653210</td>\n",
       "      <td>0.299089</td>\n",
       "      <td>5.017138</td>\n",
       "      <td>2683.703254</td>\n",
       "      <td>4.483225</td>\n",
       "      <td>0.101575</td>\n",
       "      <td>1.057864</td>\n",
       "      <td>1.782041</td>\n",
       "      <td>3234.937085</td>\n",
       "      <td>0.30003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>109.965000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>145.500000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>184.995000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>488.200000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>963.805000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>584.867500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1682.877500</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5550.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50880.880000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>46388.810000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>48241.310000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                f4           f6           f8          f18          f20  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      1.243600     1.155400     1.754200     1.074800     1.272000   \n",
       "std       1.080228     0.767964     1.925753     0.336493     0.631265   \n",
       "min       1.000000     0.000000     1.000000     1.000000     1.000000   \n",
       "25%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "50%       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "75%       1.000000     1.000000     2.000000     1.000000     1.000000   \n",
       "max      47.000000    36.000000    69.000000     5.000000    12.000000   \n",
       "\n",
       "               f21          f23          f25          f26          f27  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean    548.471622     8.411000     1.101400     1.319600     1.249600   \n",
       "std     888.582893    21.468457     0.666038     0.912153     4.793819   \n",
       "min      38.000000     0.100000     1.000000     1.000000     1.000000   \n",
       "25%     109.965000     0.160000     1.000000     1.000000     1.000000   \n",
       "50%     184.995000     0.460000     1.000000     1.000000     1.000000   \n",
       "75%     550.000000     2.770000     1.000000     1.000000     1.000000   \n",
       "max    5550.000000    99.000000    29.000000    19.000000   239.000000   \n",
       "\n",
       "          ...               f48          f52          f55           f58  \\\n",
       "count     ...       5000.000000  5000.000000  5000.000000   5000.000000   \n",
       "mean      ...       1296.837268     0.814454     1.058000    943.182078   \n",
       "std       ...       3389.653210     0.299089     5.017138   2683.703254   \n",
       "min       ...          0.000000     0.000000     0.000000      0.000000   \n",
       "25%       ...          0.000000     0.570000     0.000000      0.000000   \n",
       "50%       ...         55.920000     1.000000     0.000000      0.000000   \n",
       "75%       ...        963.805000     1.000000     1.000000    584.867500   \n",
       "max       ...      50880.880000     1.000000   103.000000  46388.810000   \n",
       "\n",
       "               f62          f63          f64          f68           f69  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000   5000.000000   \n",
       "mean      1.774800     0.009200     0.689600     1.148200   1678.807733   \n",
       "std       4.483225     0.101575     1.057864     1.782041   3234.937085   \n",
       "min       0.000000     0.000000     0.000000     0.000000     38.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000    145.500000   \n",
       "50%       0.000000     0.000000     1.000000     1.000000    488.200000   \n",
       "75%       2.000000     0.000000     1.000000     1.000000   1682.877500   \n",
       "max      66.000000     2.000000    24.000000    69.000000  48241.310000   \n",
       "\n",
       "            class  \n",
       "count  5000.00000  \n",
       "mean      0.10000  \n",
       "std       0.30003  \n",
       "min       0.00000  \n",
       "25%       0.00000  \n",
       "50%       0.00000  \n",
       "75%       0.00000  \n",
       "max       1.00000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Univariate Analysis\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y for training data\n",
    "y = data['class']\n",
    "X = data.drop(columns = ['class','date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f2', 'f5', 'f7', 'f10', 'f11', 'f12', 'f15', 'f16', 'f19', 'f28', 'f29', 'f31', 'f34', 'f35', 'f37', 'f40', 'f42', 'f46', 'f50', 'f51', 'f54', 'f56', 'f60', 'f61', 'f66']\n"
     ]
    }
   ],
   "source": [
    "# Categorical boolean mask\n",
    "bool_feature = X.dtypes==bool # filter categorical columns using mask and turn it into a list\n",
    "#print(categorical_feature)\n",
    "bool_cols = X.columns[bool_feature].tolist()\n",
    "print(bool_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[bool_cols] *= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['f13'] = X['f13'].apply(lambda x: np.nan if x==\"no_data\" else x)\n",
    "X['f14'] = X['f14'].apply(lambda x: np.nan if x==\"no_data\" else x)\n",
    "X['f36'] = X['f36'].apply(lambda x: np.nan if x==\"no_data\" else x)\n",
    "\n",
    "X = X.replace(np.nan, 0)\n",
    "X['f13'] = X['f13'].astype('int64')\n",
    "X['f14'] = X['f14'].astype('int64')\n",
    "X['f36'] = X['f36'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f1', 'f3', 'f9', 'f17', 'f22', 'f24', 'f32', 'f33', 'f38', 'f39', 'f41', 'f43', 'f44', 'f45', 'f49', 'f53', 'f57', 'f59', 'f65', 'f67']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature = X.dtypes==object# filter categorical columns using mask and turn it into a list\n",
    "#print(categorical_feature)\n",
    "categorical_cols = X.columns[categorical_feature].tolist()\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f3</th>\n",
       "      <th>f9</th>\n",
       "      <th>f17</th>\n",
       "      <th>f22</th>\n",
       "      <th>f24</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>f41</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f49</th>\n",
       "      <th>f53</th>\n",
       "      <th>f57</th>\n",
       "      <th>f59</th>\n",
       "      <th>f65</th>\n",
       "      <th>f67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1  f3  f9  f17  f22  f24  f32  f33  f38  f39  f41  f43  f44  f45  f49  \\\n",
       "0   2   0   0    0    3    0    0    0    0    3    0    3    0    0    0   \n",
       "1   2   0   0    0    2    0    0    0    0    3    0    3    0    0    0   \n",
       "2   1   1   0    0    3    0    0    0    0    2    0    0    0    0    0   \n",
       "3   0   1   0    0    3    0    0    0    2    2    0    2    0    0    0   \n",
       "4   2   1   0    1    3    0    0    0    0    2    0    0    0    0    0   \n",
       "\n",
       "   f53  f57  f59  f65  f67  \n",
       "0    1    0    1    0    1  \n",
       "1    1    0    1    0    1  \n",
       "2    0    0    1    0    1  \n",
       "3    0    0    1    0    1  \n",
       "4    1    0    1    0    1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "# apply le on categorical feature columns\n",
    "X[categorical_cols] = X[categorical_cols].apply(lambda col: \n",
    "                                     le.fit_transform(col))\n",
    "X[categorical_cols].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3152\n",
      "1     348\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Distribution of Labels on train data\n",
    "xy=y_train.value_counts()\n",
    "print(xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier accuracy: 94.73333333333333%\n",
      "Logistic Regression accuracy: 85.53333333333333%\n",
      "K Nearest Neighbors Classifier accuracy: 94.13333333333334%\n",
      "Random Forest Classifier accuracy: 93.73333333333333%\n",
      "Gradient Boosting Classifier accuracy: 94.0%\n",
      "XGBoost Classifier accuracy: 93.26666666666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Purnendu\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Applying various Classification algorithms without doing variable reductions\n",
    "accuracy_scores = np.zeros(6)\n",
    "\n",
    "# Support Vector Classifier\n",
    "clf = SVC(class_weight = 'balanced').fit(X_train, y_train)\n",
    "prediction1 = clf.predict(X_test)\n",
    "accuracy_scores[0] = accuracy_score(y_test, prediction1)*100\n",
    "print('Support Vector Classifier accuracy: {}%'.format(accuracy_scores[0]))\n",
    "\n",
    "# Logistic Regression\n",
    "clf = LogisticRegression(class_weight = 'balanced').fit(X_train, y_train)\n",
    "prediction2 = clf.predict(X_test)\n",
    "accuracy_scores[1] = accuracy_score(y_test, prediction2)*100\n",
    "print('Logistic Regression accuracy: {}%'.format(accuracy_scores[1]))\n",
    "\n",
    "# K Nearest Neighbors\n",
    "clf = KNeighborsClassifier(                                   ).fit(X_train, y_train)\n",
    "prediction3 = clf.predict(X_test)\n",
    "accuracy_scores[2] = accuracy_score(y_test, prediction3)*100\n",
    "print('K Nearest Neighbors Classifier accuracy: {}%'.format(accuracy_scores[2]))\n",
    "\n",
    "# Random Forest\n",
    "clf = RandomForestClassifier(class_weight = 'balanced').fit(X_train, y_train)\n",
    "prediction4 = clf.predict(X_test)\n",
    "accuracy_scores[3] = accuracy_score(y_test, prediction4)*100\n",
    "print('Random Forest Classifier accuracy: {}%'.format(accuracy_scores[3]))\n",
    "\n",
    "# Gradient Boosting\n",
    "clf = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "prediction5 = clf.predict(X_test)\n",
    "accuracy_scores[4] = accuracy_score(y_test, prediction5)*100\n",
    "print('Gradient Boosting Classifier accuracy: {}%'.format(accuracy_scores[4]))\n",
    "\n",
    "#XGBoosting\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight = 9.06)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "prediction6 = xgb_model.predict(X_test)\n",
    "accuracy_scores[5] = accuracy_score(y_test, prediction6)*100\n",
    "print('XGBoost Classifier accuracy: {}%'.format(accuracy_scores[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy of various algorithms')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = cm.rainbow(np.linspace(0, 2, 9))\n",
    "labels = ['SVC', 'LR', 'KNN', 'RF', 'GBM', 'XGB']\n",
    "plt.bar(labels,\n",
    "        accuracy_scores,\n",
    "        color = colors)\n",
    "plt.xlabel('Classifiers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of various algorithms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1339    9]\n",
      " [  56   96]]\n",
      "[[1331   17]\n",
      " [  90   62]]\n",
      "[[1337   11]\n",
      " [  77   75]]\n",
      "[[1335   13]\n",
      " [  76   76]]\n",
      "[[1331   17]\n",
      " [  73   79]]\n",
      "[[1280   68]\n",
      " [  33  119]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf1 = confusion_matrix(y_test, prediction1)\n",
    "print(conf1)\n",
    "conf2 = confusion_matrix(y_test, prediction2)\n",
    "print(conf2)\n",
    "conf3 = confusion_matrix(y_test, prediction3)\n",
    "print(conf3)\n",
    "conf4 = confusion_matrix(y_test, prediction4)\n",
    "print(conf4)\n",
    "conf5 = confusion_matrix(y_test, prediction5)\n",
    "print(conf5)\n",
    "conf6 = confusion_matrix(y_test, prediction6)\n",
    "print(conf6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-afb632257412>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-afb632257412>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    plt.show().\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# check validation statistics (Classification Summary)\n",
    "print(classification_report(y_test, prediction6))\n",
    "# Plot confusion Matrix\n",
    "skplt.metrics.plot_confusion_matrix(y_test, prediction6, figsize=(10, 8))\n",
    "plt.show().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skplt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a4860c850ee9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ROC Curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mskplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_roc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_probas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Plot ROC Curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skplt' is not defined"
     ]
    }
   ],
   "source": [
    "# ROC Curves\n",
    "y_probas = xgb_model.predict_proba(X_test)\n",
    "skplt.metrics.plot_roc(y_test, y_probas, figsize=(10, 8))   # Plot ROC Curve\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 37)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - First\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train = slc.fit_transform(X)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train = pca.fit_transform(train)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 34)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Second\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train1 = slc.fit_transform(train)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train1 = pca.fit_transform(train1)\n",
    "print(train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 31)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Third\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train2 = slc.fit_transform(train1)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train2 = pca.fit_transform(train2)\n",
    "print(train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Fourth\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train3 = slc.fit_transform(train2)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train3 = pca.fit_transform(train3)\n",
    "print(train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 26)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Fifth\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train4 = slc.fit_transform(train3)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train4 = pca.fit_transform(train4)\n",
    "print(train4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 24)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Sixth\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train5 = slc.fit_transform(train4)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train5 = pca.fit_transform(train5)\n",
    "print(train5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 22)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Seventh\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train6 = slc.fit_transform(train5)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train6 = pca.fit_transform(train6)\n",
    "print(train6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 20)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Eightth\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train7 = slc.fit_transform(train6)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train7 = pca.fit_transform(train7)\n",
    "print(train7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 18)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Nineth\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train8 = slc.fit_transform(train7)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train8 = pca.fit_transform(train8)\n",
    "print(train8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 17)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Tenth\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train9 = slc.fit_transform(train8)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train9 = pca.fit_transform(train9)\n",
    "print(train9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 16)\n"
     ]
    }
   ],
   "source": [
    "#With Reduction technique - Eleventh\n",
    "\n",
    "# Statndard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "slc = StandardScaler()\n",
    "train10 = slc.fit_transform(train9)\n",
    "\n",
    "# Dimentionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.9, random_state = 0)\n",
    "train10 = pca.fit_transform(train10)\n",
    "print(train10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Data form above reduction dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train10, y, test_size = 0.3, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3152\n",
      "1     348\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Distribution of Labels on train data\n",
    "yy=y_train.value_counts()\n",
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier accuracy: 94.73333333333333%\n",
      "Logistic Regression accuracy: 85.53333333333333%\n",
      "K Nearest Neighbors Classifier accuracy: 94.13333333333334%\n",
      "Random Forest Classifier accuracy: 93.06666666666666%\n",
      "Gradient Boosting Classifier accuracy: 94.0%\n",
      "XGBoost Classifier accuracy: 93.26666666666667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Purnendu\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Applying various Classification algorithms without doing variable reductions\n",
    "accuracy_scores = np.zeros(6)\n",
    "\n",
    "# Support Vector Classifier\n",
    "clf = SVC(class_weight = 'balanced').fit(X_train, y_train)\n",
    "prediction1 = clf.predict(X_test)\n",
    "accuracy_scores[0] = accuracy_score(y_test, prediction1)*100\n",
    "print('Support Vector Classifier accuracy: {}%'.format(accuracy_scores[0]))\n",
    "\n",
    "# Logistic Regression\n",
    "clf = LogisticRegression(class_weight = 'balanced').fit(X_train, y_train)\n",
    "prediction2 = clf.predict(X_test)\n",
    "accuracy_scores[1] = accuracy_score(y_test, prediction2)*100\n",
    "print('Logistic Regression accuracy: {}%'.format(accuracy_scores[1]))\n",
    "\n",
    "# K Nearest Neighbors\n",
    "clf = KNeighborsClassifier().fit(X_train, y_train)\n",
    "prediction3 = clf.predict(X_test)\n",
    "accuracy_scores[2] = accuracy_score(y_test, prediction3)*100\n",
    "print('K Nearest Neighbors Classifier accuracy: {}%'.format(accuracy_scores[2]))\n",
    "\n",
    "# Random Forest\n",
    "clf = RandomForestClassifier(class_weight = 'balanced').fit(X_train, y_train)\n",
    "prediction4 = clf.predict(X_test)\n",
    "accuracy_scores[3] = accuracy_score(y_test, prediction4)*100\n",
    "print('Random Forest Classifier accuracy: {}%'.format(accuracy_scores[3]))\n",
    "\n",
    "# Gradient Boosting\n",
    "clf = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "prediction5 = clf.predict(X_test)\n",
    "accuracy_scores[4] = accuracy_score(y_test, prediction5)*100\n",
    "print('Gradient Boosting Classifier accuracy: {}%'.format(accuracy_scores[4]))\n",
    "\n",
    "#XGBoosting\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight = 9.06)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "prediction6 = xgb_model.predict(X_test)\n",
    "accuracy_scores[5] = accuracy_score(y_test, prediction6)*100\n",
    "print('XGBoost Classifier accuracy: {}%'.format(accuracy_scores[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Accuracy of various algorithms')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = cm.rainbow(np.linspace(0, 2, 9))\n",
    "labels = ['SVC', 'LR', 'KNN', 'RF', 'GBM', 'XGB']\n",
    "plt.bar(labels,\n",
    "        accuracy_scores,\n",
    "        color = colors)\n",
    "plt.xlabel('Classifiers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of various algorithms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1298   50]\n",
      " [  29  123]]\n",
      "[[1163  185]\n",
      " [  32  120]]\n",
      "[[1337   11]\n",
      " [  77   75]]\n",
      "[[1341    7]\n",
      " [  97   55]]\n",
      "[[1331   17]\n",
      " [  73   79]]\n",
      "[[1280   68]\n",
      " [  33  119]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf1 = confusion_matrix(y_test, prediction1)\n",
    "print(conf1)\n",
    "conf2 = confusion_matrix(y_test, prediction2)\n",
    "print(conf2)\n",
    "conf3 = confusion_matrix(y_test, prediction3)\n",
    "print(conf3)\n",
    "conf4 = confusion_matrix(y_test, prediction4)\n",
    "print(conf4)\n",
    "conf5 = confusion_matrix(y_test, prediction5)\n",
    "print(conf5)\n",
    "conf6 = confusion_matrix(y_test, prediction6)\n",
    "print(conf6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
